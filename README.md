## Развертывание проекта

Для успешного развертывания проекта можно использовать несколько методов. В данном документе описаны шаги для локального развертывания проекта, а также дополнительные настройки для взаимодействия с сервером.

#### Локальное развертывание

1. **Установка Python:**
   - Убедитесь, что на вашем компьютере установлена Python версии 3.11 или выше. Вы можете проверить версию Python, выполнив команду:
     ```bash
     python --version
     ```
   - Если Python не установлен или версия не соответствует требуемой, скачайте и установите его с официального сайта Python.

2. **Создание виртуального окружения:**
   - Рекомендуется использовать виртуальное окружение для изоляции зависимостей проекта. Создайте виртуальное окружение, выполнив команду:
     ```bash
     python -m venv venv
     ```
   - Активируйте виртуальное окружение:
     - Для Windows:
       ```bash
       venv\Scripts\activate
       ```
     - Для macOS и Linux:
       ```bash
       source venv/bin/activate
       ```

3. **Установка зависимостей:**
   - Установите необходимые пакеты, выполнив команду:
     ```bash
     pip install fastapi ultralytics uvicorn numpy opencv-python
     ```
   - Убедитесь, что все пакеты установлены корректно, выполнив команду:
     ```bash
     pip list
     ```

4. **Запуск проекта:**
   - Запустите основной скрипт проекта, выполнив команду:
     ```bash
     python main.py
     ```
   - После успешного запуска, вы должны увидеть сообщение о том, что сервер запущен и готов к приему запросов.

5. **Проверка работы:**
   - Откройте веб-браузер и перейдите по адресу:
     ```
     http://127.0.0.1:8000
     ```
   - Если все настроено правильно, вы увидите сообщение, подтверждающее работу сервера.

6. **Документация:**
   - Для доступа к документации API, перейдите по адресу:
     ```
     http://127.0.0.1:8000/docs
     ```
   - Здесь развернут интерфейс Swagger, который позволяет вам просматривать и тестировать доступные эндпоинты API.

#### Настройка взаимодействия с сервером

1. **Указание адреса сервера:**
   - Для настройки взаимодействия с сервером, откройте файл `ImageUploader.cs`, расположенный по пути:
     ```
     AutoARAplicationLite/Assets/ImageUploader.cs
     ```
   - Найдите строку, где указывается базовый URL сервера, и измените её на:
     ```csharp
     string baseUrl = "http://127.0.0.1:8000";
     ```
   - Это позволит клиентскому приложению подключаться к локально запущенному серверу.

2. **Использование скомпилированного модуля:**
   - Убедитесь, что скомпилированный модуль `netstandard` доступен по пути:
     ```
     AutoARAplicationLite/Assets/Plugins/netstandard2.1
     ```
   - Этот модуль необходим для взаимодействия с сервером и должен быть включен в проект.


## Описание проекта

**AutoARExperience** — это интерактивный музей "Автомобильной техники" с элементами дополненной реальности (AR). Проект направлен на создание мобильного приложения, которое позволит посетителям музея взаимодействовать с экспонатами, получая дополнительную информацию и визуальные эффекты.

### Основные функции:
- **Дополненная реальность (AR)**: Добавление виртуальных элементов к реальным экспонатам.
- **Интерактивные элементы**: Пользователи могут взаимодействовать с экспонатами через приложение.
- **Информационные карточки**: Отображение подробной информации об экспонатах.
- **3D модели**: Визуализация 3D моделей автомобилей.

### Технологии:
- **Unity**: Для разработки мобильного приложения.
- **OpenCV**: Для обработки изображений и распознавания объектов.
- **Vuforia Engine**: Для дополненной реальности.
- **WebSocket-Sharp**: Для передачи данных между клиентом и сервером.
- **FastAPI**: Для серверной части на Python.
- **MAUI/C#**: Для клиентской части на мобильном устройстве.

### Рабочий процесс:
1. **Клиент** получает изображение с камеры.
2. **Клиент** отправляет изображение на сервер.
3. **Сервер** обрабатывает изображение и распознает объекты.
4. **Сервер** отправляет информацию о распознанном объекте на клиент.
5. **Клиент** формирует графический контент с дополнительной информацией и привязывает его к оригинальному объекту на изображении.

## Команда и распределение задач

### Участник 1: Разработчик клиентской части (MAUI/C#)
- **Задачи:**
  - Разработка интерфейса приложения.
  - Интеграция камеры для получения изображений.
  - Отправка изображений на сервер.
  - Прием и отображение данных от сервера.
  - Привязка дополненной реальности к экспонатам.

### Участник 2: Разработчик серверной части (Python/FastAPI)
- **Задачи:**
  - Разработка API для обработки изображений.
  - Распознавание объектов с использованием OpenCV.
  - Возвращение информации о распознанных объектах.
  - Обработка запросов от клиента.
  - Логирование и мониторинг.

### Участник 3: Разработчик дополненной реальности (Unity)
- **Задачи:**
  - Интеграция Vuforia Engine для AR.
  - Создание и настройка 3D моделей.
  - Привязка 3D моделей и интерактивных элементов к экспонатам.
  - Тестирование и оптимизация AR-функционала.

### Участник 4: Разработчик обработки изображений (OpenCV)
- **Задачи:**
  - Разработка алгоритмов для распознавания объектов.
  - Оптимизация алгоритмов для быстрого и точного распознавания.
  - Интеграция OpenCV с серверной частью.
  - Тестирование и отладка алгоритмов.

### Участник 5: Менеджер проекта и QA
- **Задачи:**
  - Координация работы команды.
  - Планирование и контроль сроков.
  - Тестирование приложения на всех этапах разработки.
  - Сбор и анализ обратной связи.
  - Документирование процесса разработки и результатов.

## Дополнительные ресурсы

### 3D модели
- [Free3D.com](https://free3d.com/3d-model/vaz-2801-17142.html)

### Инструменты
- [Unity Asset Store](https://assetstore.unity.com/packages/tools/integration/opencv-plus-unity-85928#description)
- [Vuforia Engine](https://assetstore.unity.com/packages/templates/packs/vuforia-engine-163598?srsltid=AfmBOoqJbLSbHrRDsjWIJK2cBoZSsdijGr3A3X1KFJgdPPkQ4dVK5tH1)
- [WebSocket-Sharp](https://github.com/sta/websocket-sharp)
- [FastAPI](https://github.com/PasoUnleashed/FastAPI.Net)


## Что не удалось сделать

В процессе разработки проекта мы столкнулись с рядом ограничений и технических сложностей, которые не позволили нам полностью реализовать запланированные функции. Вот более подробное описание этих проблем:

#### 1. Использование Дополненной Реальности для Отображения 3D Объектов

Изначально мы планировали интегрировать дополненную реальность (AR) для отображения 3D объектов. Однако, использование OpenCV для этой цели оказалось более сложным, чем ожидалось. Основные проблемы, с которыми мы столкнулись:

- **Несовместимость с Последними Версиями OpenCV:**
  - В последних версиях OpenCV (4.x) были удалены ряд инструментов, которые необходимы для работы с дополненной реальностью. Большинство доступных руководств и рекомендаций основаны на версии 3.x, где эти инструменты еще присутствуют.
  - Официальная документация также указывает на использование версии 3.x, но установить её через Homebrew стало невозможно с начала 2024 года.

- **Сложности с Компиляцией из Источников:**
  - Вариант скомпилировать OpenCV из исходников был рассмотрен, но это требовало значительного времени и ресурсов, что не подходило для условия хакатона.

- **Проблемы с macOS:**
  - Work с OpenCV на macOS оказался не столь удобным. В Windows, наоборот, установка и настройка необходимых инструментов проходят гораздо проще. Поэтому, в качестве рекомендации, я бы посоветовал использовать Windows для подобных проектов.

#### 2. Использование ARUco Меток и Плагинов

Как альтернативный вариант, мы рассмотрели использование ARUco меток и набора плагинов для Unity, таких как:

- **[OpenCV plus Unity](https://assetstore.unity.com/packages/tools/integration/opencv-plus-unity-85928?srsltid=AfmBOopWXIRREdWB2gNSoBQksN2O1gK-dL0GGUyFGoN4d7Mt0YbY6VYx):**
  - Пакет, обеспечивающий интеграцию OpenCV с Unity, что могло бы упростить работу с изображениями и видео.

- **[AR Marker Detector](https://assetstore.unity.com/packages/templates/tutorials/ar-marker-detector-80086):**
  - Пакет для обнаружения и отслеживания ARUco меток в Unity.

Однако, эксперименты показали, что качество встроенной камеры ноутбука не достаточно высокое для надежного распознавания меток. Процесс распознавания был нестабильным и часто приводил к ошибкам. Эти технические ограничения привели нас к решению отказаться от этого подхода в рамках хакатона.

### Выводы и Рекомендации

- **Использование Windows:**
  - Для проектов, требующих работы с OpenCV и дополненной реальностью, рекомендуется использовать операционную систему Windows, так как установка и настройка необходимых инструментов на ней проходят гораздо проще и стабильнее.

- **Альтернативные Платформы:**
  - Рассмотрите использование других платформ и библиотек, таких как ARKit для iOS или ARCore для Android, которые предоставляют более продвинутые инструменты для работы с дополненной реальностью.

- **Качество Камеры:**
  - Для более точного и стабильного распознавания меток и объектов рекомендуется использовать внешние камеры с высоким разрешением.

Несмотря на эти ограничения, мы продолжим работать над проектом и искать оптимальные решения для реализации запланированных функций.

## Лицензия

Этот проект лицензирован под лицензией [MIT License](LICENSE).
